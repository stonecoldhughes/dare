Changes:
    
    replace kernel_data with an array of vectors.

What subjects do you need to learn...

    1. Design patterns.
    2. Embedded design.
    3. Physics
    4. Probability and stats
    5. Complex analysis
    6. Graph theory
    7. Algorithms


install mkl again... make sure you can compile plasma
install the module system on your mac. Write a module file for plasma
Update the cmake lists and stuff
Get a working installation of the tracer with the same plasma used on saturn.
move it all over to plasma and run it.


    Current Development:

        main.c has a problem size and runs matrices in a loop around this
        size. Have a couple main.c programs for different problems
        (small matrices, many iterations vs many iterations, large matrices)

        1. Show that the autotuner approximates real runs by making a graph
           that plots both for the same tile size and increasing problem
           size. Find the window of tile size, problem size, and problem type
           that it approximates the best for. Investigate How small of a
           kernel fraction can be used and still get good results. Make a
           testing script that makes all this easy.
        
        2. The autotuner script runs the same problem with different
           tile size values and selects the fastest one. Hook plasma_init()
           and call plasma_set() inside to change the values.
        
    Fixes:
        
        repeated code when calling root.find('use_default')
        set default output to true when needed.
        Fix code indentation.
        add autogeneration code warning at the top of each autogenerated file
        add m, n, and k for each call to kernel_data

    use_default set in trace_config on 161
    moving it to write_autogen_cpp line 299
    Note: plasma_types.h contains definition for enum
    PlasmaNb

    context.c contains plasma_set, which sets the parameter.

    Test your hypothesis:

        Write a main.c that runs plasma_dgemm and cholesky many times in a loop
        with problem sizes that deviate from a size given on the command line.
        The amount of allowable deviation is also provided on the command line.

        Write a python script that runs and times this program with progressively
        higher problem sizes.

        Then run and time the program with the same tile size and sweeping problem
        sizes but with the autotuner set to run different percentages of kernels.

        If the curves have maxima and minima at the same values, it means it's a
        good autotuner. Otherwise it isn't.

        The point of all this is to show that my kernel sampling accurately
        represents the runtime characteristics of the entire program.

        Determine what is the minimum problem size that gives relevant results.
        Small runs will not help very much. At a small enough matrix size,
        the overhead may equal the actual work. Investigate these cases.

    Develop the autotuning script:
        
        The autotuner runs in two passes. The first runs with each core_blas call
        stripped of all functionality. This gives the baseline overhead time, which
        will be subtracted from each autotuner pass.

        The second pass changes PlasmaNb iteration to have a
        different NB tile size. It plots the times for all these. The program is run
        while linked to the dare library in autotune mode this time

    Develop the dare library to support autotuning:

        Rewrite autogen.py. The xml config file specifies a kernel_fraction. This
        determines what fraction of kernels should run. Each kernel picks a random
        number. If it is within the proper range, run the kernel. If not, skip it.
        Possibly store a large sequence of numbers in an array and cycle through
        it to save the overhead of the function call? Or trust the stl. Idk.

    Write a better visualizer in plot.ly:
        
        self-explanatory

    Do your Architecture hw

    Rewrite autogen.py to configure for autotuning

    final version of sweep.py:
        
        iterate over all tile sizes and problem sizes.
        for each new tile size, rewrite the LUA file.
        
        time
        run main with arg
        time
        store point

        time
        run main_dare
        time
        store point

        then use plot.ly to plot it all.

        ^this all assumes that the program is making calls on a matrix of
        the same shape. What if it is working with matrices of odd shapes?

        **what if you do a run with no kernel work done? This tells you
        the baseline overhead of the program. You could subract this from
        each timing point and focus only on the actual core_blas calls

        What should main do? Dgemm and Cholesky repeatedly with a couple different
        tile sizes? Yes, probably that. Do gemm and cholesky with different tile
        sizes.

        For each kernel... I count up how many operations it computes. I assume 


        autotuner runs in 2 passes: first pass is to determine the overhead
        of function calls. No core_blas kernels run at at all. Second pass is
        to actually run the program with different tile sizes. The test program
        we want to run it on will have a mix of different problem sizes for
        dgemm and cholesky. This should be repeated with other kernels too.
        Record the number of each kernel that ran.


        Begin the second pass. Each kernel calls rand(). If it falls within the
        runnable range, run it. The runnable range depends largely on the number
        of kernels of that type that ran. If it is a small number, run them all.
        If it is large but not huge, run several. If it is big enough, you can
        get away with running a small number.

        Write your test program. It needs random sizes for matrices for dgemms
        and choleskys. Test to make sure it's running right. Give it distributions
        for number of kernels of each size.

        Run that test program on different sizes of m. Result should always be a
        square matrix. Run it within the framework of the python program that also
        times it. The reference time will be a baseline on the graph. Have 2
        versions of the program. One where it is linked with core_blas and one
        where it's also linked with your dare library. Once you have timings,
        Rewrite autogen.py so it works for the autotuner and run it alongside the
        autotuner. That will be the test that verifies that what you're doing works.

        Next you actually have to implement the autotuner. For the autotuner, your
        script needs to tune it to the saturn cluster. The initial script needs
        to rewrite the LUA file each time and record the runtime. Then it needs to
        repeat that.


    Have the python sweep script for autotuning, it runs a PLASMA application
    over and over and gets timing info for it.
    skip_ratio determines what fraction of kernels are actually run.
    I hypothesize that this ratio will also correspond roughly to the time ratio
    between actual runs and one with skip_ratio implemented.

    Code-wise, you need to subclass dare_base. What will you need?

    1. Update autogen.py to compile the project for runtime autotuning.
    2. create autotune.py. It takes the executable name and runs it with
       the library with different tile sizes and times it all. Have autotune.py
       run autogen.py in the background?
    3. Make sure your stuff still works with the most current version of PLASMA


    autogen.cpp needs to contain the constructor for dare_base
    instead.

        1. Talk to Sam about the technical report
        2. Work on a plotly visualizer.
        3. 
        Don't forget to initialize kernel_mut and kernel_data.
        Test to make sure this all works.

        The watchdog function has access to the array of condition variables.
    0. Check the order somehow.
    1. Look into score P's visualizer for displaying stuff.
    
    hook()
    {
        lock();
    }

    You need a different visualization strategy - maybe an openGL shader?

    Make the default behavior come from a module, so it will be an example that can be copied.

    Make a simulator module.


    1. Make your tracing framework more modularized.
    2. Work on a module for simulation

    Changes to make to the PLASMA library:
        1. In Mark's Makefile, change the findstring to have an empty string argument.
        2. Change PLASMA to have the attribute weak stuff.
        3. Make the final contribution to PLASMA!

    To link with a tracing C file, you must declare the functions as extern. 
        You'll need a new case for this. Add the file extension type and the function declaration.
    To link with a tracing .cpp file, you must include the relevant header <--- done
    Get rid of -g and -flat_namespace in the CMakeLists.txt files
    I am going to combine autogen.py and cmake.py into a single script.
    Would it work without linking in coreblas and plasma? Because that is already linked in libprofile.dylib? Try it 
    Build instructions:
        1. Change make.inc.mkl-gcc. Change compiler to actual gcc
        2. Move control files into coreblas in the main plasma makefile
        2. Change tools/lua-5.shit/src/Makefile to include an option for building LUA_SO. Make sure to use "noexpandtab"
           in your text editor so the makefile sees a tab and not 4 spaces.
        3. Build LUA_SO
        4. Change the install name of liblua.so, libplasma.so, and libcoreblas.so to the directory in which they reside.
           This is so things work on macosx, I don't know if this has to be done on linux. But probably not.

        5. Run weak_attribute.py to add weak symbols to plasma
        6. To get trace.c to work: Split it up into a header file and a C file.
        New features you have to add to make it work:
        7. Give the script the name of the header file and it will find the directory.

    1. Create the repo on your home machine. Make all changes necessary to build it and have weak symbols, and to have trace broken up.
    2. Create a directory and put your stuff in it.
    3. Make sure it works.
    4. Push to your bitbucket repo
    5. Make a pull request to the main PLASMA one.
    6. Make a wiki entry.

    Deployment instructions:
        
        1. Change tracing to plasma_trace.h and trace.c
        2. Add weak symbol linkage into PLASMA
        3. Point out the code_gen bug
        4. Put your stuff on Bitbucket

    Make a new CMakeLists.txt in which PLASMA init
    I should be able to link with my library and a config file and it produces the trace output.
        1. Build PLASMA
        2. Build the tracer with the config file.
        3. Run your program through my CMake interface.
        4. Get the output file

    Configurability with CMake:
        
        1. Make the default built-in case configurable.
            
            A. Add a tag to tell whether or not to use the default.
            B. This tag will be interpreted the same way as others.
            C. The tag will have a color map tag associated with it.
            D. This is 2nd priority.
        
        2. New CMake options:
            
            1. Split up CMake for the main() you're testing and the CMake for you tracing library.
            2. add trace files as a CMake option - a .h file and a .c file
            3. Then it should work!

    Convert the core kernel list into a map and it should work.
    1. Finish the Tracer
    2. Get a Job
    3. Write the data mining initial report
    4. Markov Chains homework and test

    You have watched game of thrones season 6 episode 9
    Mely said bellfigentent hahahahaha
    MIT Open Courseware:
        1. Prob and stats
        2. Numerical Mathematics
        3. Matrix calculus & Matrix methods
        4. Mathematical modeling & Data Analysis
        5. Optimization

    Later:
        1. Leadership
        2. Physics
        3. Chemistry


    List of things to do:
        
        1. Markov take-home exam
        2. Data mining hw
        3. Data mining keras research
        4. PLASMA Tracer development. Test to see if it is stable
        5. Make sure you're on track to get your master's degree in time!


    PLASMA next steps:

        Set up the makefile to run in CMake to rebuild PLASMA if anything goes wrong.
        Pull in from Bitbucket, make changes, ensure you can compile, then make a pull request.
        Add your project to the larger PLASMA repository. 
        Ask about how to test it.
        Possiby work on visualization.




    Next: Add weak symbol linkage into core_blas via iterating the directory with a python script. Ask plasma_dev about it.


    Next Step: 
    Implement TensorFlow with MAGMA
    Email Arvind Ramanathan

    Work Project:
        1. Accelerating deep learning with tensor operations
        2. Pytorch
        3. Theano
        4. Tensorflow

    Action Item: Compile Tensorflow with Magma underneath it. Ask them about that.

    Tracer Plan:

        1. Move everything to headers manually to ensure it works. Then you'll be generating them. Do it in place.
        2. Create a new branch called "autogen"
        Create a script that parses a core_z* header file. It creates wrappers like the one below
        as well as the correct parameter types.

        Info needed to add support for 1 kernel:
            1. Function enum
            2. A return type
            3. An atomic counter
            4. A function pointer
            5. A parameter list

            Note: (*ptr)(); <--- this works for a variable number of arguments. Any number of arguments works.

    Captain! Hook functions out of libcoreblas instead of libplasma. 

    1. find out what version of gcc is needed to run OMPT
    2. Find out why you had to use ompt_control() - thread safety, same mechanism to record times
    3. Higher code quality.

OpenMP Runtime notes:

    1. what is kmpc_micro?

__attribute__ (( weak ))

    Books to get:

        1. Drive
    
    Visualization:

        1. look into matplotlib
        2. Look into svg.charts

    Current status:

        1. I cannot hook core_* functions because of some issue with how it is built.
        2. I need to know how to create a Gantt chart like the ones Blake uses.
        3. I need to know how to determine which functions are supposed to run in parallel. Will this require OMPT modification?
        4. Apply for jobs!!!

    Try to work for Nutanix next summer!

    Tasks:
        
         
    Project steps:
        
        1. Set up a git repo.
        2. Change to hooking core functions.
        3. Create a test program an investigate parallel regions and possibly using that as an identifier?
        4. Investigate tracing formats and make a graph out of all of it somehow.


    Project meeting input:

        1. Decouple kernel modeling and fake timeline generation.
        2. Work with Mike Tsai to automatically create core_* wrappers to integrate into your tracing framework.
        3. The granularity of the kernels you're hooking is too fine. You need to hook core_* functions instead of
           core_omp* or MKL cblas_* kernels.
        4. Start a git repo for this on Hydra.

        5. Two threads now exist: A tracer and a simulator. You should work on the tracer first.

        6. The tracer needs a visualizer.
        7. The simulator needs parallel region testing first. If this fails, I don't know what to do.
        8. Read all of OpenMP.
        9. Tune things with BEASTLang? Head node and computer node? Cross compiling? Parallel compiling? nvcc involved.
        10. Apparently SVG doesn't scale. CSV file. OTF2. Open Tracing Format 2?
        11. Start Applying for jobs now too.

    Movies:

        Drag me to hell.
        Last house on the left.
        red state?


    Spanish
    Christmas Presents
    Resume & Spanish
    Topcoder
    Clean Room
    Clean Up Leaves
    Gingerbread
    Ice Skating
    Grad classes next semester
    Play Piano
    Make a Twitter
    Organize phone pictures
    Get back on your instagram game
    Get "Cracking the Coding Interview"

    oman systems
    universal robotics
    cicayda
    tsw automation

    "reset" to reset the terminal

    melv vibe
    vanic make me fade
    sia breathe me in
    major lazer be together
    memtrix all you are
    illenium without you
    memtrix clouds in commune
    oh be clever
    tom day
    uppermost mistakes
    ryder
    exgf
    arkasia
    501

    Places to take Mely:

        1. Melting Pot
        2. Balter's Beerworks
        3. Ruth's Chris
        4. Chesapeake's
        5. The Wine Bar with Alex(?)
        6. Go skiing!
        7. Dollywood
        8. Believe it or not
        9. Theme parks around the country
